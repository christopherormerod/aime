[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Generative AI in Education and Measurement",
    "section": "",
    "text": "Generative AI in Measurement and Education\nThis website is a placeholder for the Special Interest Group on AI in Measurement and Education (GAIME)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Generative Artificial Intelligence in Measurement and Education (GAIME)\nThe recent explosion of “Generative AI” has broad and deep implications for Education Measurement. By “Generative AI” we mean algorithms that create new text, images, or sound using machine learning algorithms trained on previous existing samples of that data. This technology is already in operational use in assessments and learning solutions and is being rapidly developed.  At the same time, it brings significant challenges to foundational principles in measurement validity, fairness, and reliability. With evidence and constructs constantly recreated, and data not representative nor static, many concepts of measurement and practices to implement them need to be rethought.\nGrounding innovation with principles from measurement can help to reduce the risk of these new approaches, improve their impact on student learning, and ensure that students from minoritized communities are not harmed, without rejecting their potential value. This genie will not be put back into its bottle.  Instead, measurement experts can help shape these solutions, collaboratively identifying important areas of focus and sharing innovative solutions. \nThis special interest group (SIGIME) seeks to advance the theoretical and applied research into Generative AI of educational measurement by bringing together data scientists, psychometricians, education researchers, and other interested stakeholders. The SIGIME will discuss current practices in using Generative AI, approaches to evaluate their precision/accuracy, and areas where more foundational research is required into the way we test and measure educational outcomes. This group seeks to create a strong professional identity and intellectual home for those interested in the use of AI in many areas, including automated scoring, item evaluation, validity studies, formative feedback, and generative AI for automated item generation. A critical initial responsibility is to ensure that there are guidelines around FATE (fair, accountable, transparent, and ethical) principles (MAS, 2018) for applying AI in measurement. Further, the interpretability of machine learning models is often a difficulty in evaluating the validity of these methods using conventional psychometric approaches, although there is active research in this area (Dorsey & Michaels, 2022). \nWe suggest three initial applied areas for exploration: \n\nItem Generation. This new technology is rapidly changing the way we think about education and problem-solving. With generative AI, the ability to create an infinite item pool is within our grasp and one that is customized to the interests or social context of the learner. However, some important ethical and psychometric considerations need to be addressed. How do we filter this pool for the best items? What are our standards of validity and accuracy when there is no baseline? How should assessment item development processes be designed? It is important for those of us who understand these systems best to help educators and test developers make informed decisions about how to use generative AI fairly and appropriately.\nAutomated scoring of open-ended items. Automated Scoringis possibly the most widely used application of AI in education, and has been identified as the top use of AI published in measurement journals (Zheng et. all, 2023). There has been a major shift in the past few years in the methods used. The development and incorporation of large language models (LLMs) in automated scoring systems have led to substantial increases in scoring accuracy and increased flexibility to generalize models to new items with a lower training effort. However, LLMs are difficult to interpret and have a greater risk of bias. Since LLMs are trained on large amounts of data that is not from students (fortunately), this introduces new ways in which scoring engines could be biased. As we move forward, we need to ensure that using LLMs in automated scoring remains fair and equitable.\nFormative Feedback. In many contexts, assessment is rapidly moving from an isolated activity to one that is embedded within the learning experience. As AI methods continue to advance, an open area of research as to how we can leverage AI to provide students with improved diagnostic feedback. Integrating AI-based tools into automated writing evaluation (AWE) systems requires that the feedback returned is grounded in educational theory. Dialogue between data scientists, educators, and psychometricians is key to ensuring that AI is utilized to improve educational outcomes. A special interest group within the NCME could provide an appropriate forum for these discussions. \n\nGenerative AI is taking the world by storm, and we believe NCME can make a deep and substantive contribution to how this technology is used in education.  A special interest group on Artificial Intelligence (AI) in Measurement and Education would provide a timely forum for researchers and practitioners in the use of AI in Education and Measurement to share their work, discuss challenges, and develop best practices. \n\nWorks Referenced\nDorsey, D. W., & Michaels, H. R. (2022). Validity Arguments Meet Artificial Intelligence in Innovative Educational Assessment: A Discussion and Look Forward. Journal of Educational Measurement, 59(3), 389–394.https://doi.org/10.1111/jedm.12330\nZheng, Y., Nydick, S., Huang, S., & Zhang, S. (2023, April 12). MxML (Exploring the paradigmatic relationship between measurement and machine learning in the history, current time, and future): Current state-of-the-field. NCME, Chicago, IL."
  },
  {
    "objectID": "gaime/about.html",
    "href": "gaime/about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "gaime/index.html",
    "href": "gaime/index.html",
    "title": "Generative AI in Education and Measurement",
    "section": "",
    "text": "Generative AI in Measurement and Education\nGenerative AI is a rapidly developing field with the potential to revolutionize education. By generating personalized learning experiences, generative AI can help students learn more effectively and efficiently.\nOne of the most promising applications of generative AI in education is in the area of assessment. Generative AI can be used to create personalized assessments that are tailored to the individual student’s needs. This can help students to learn more effectively by providing them with feedback that is relevant to their current level of understanding.\nIn addition to assessment, generative AI can also be used to create personalized learning experiences. For example, generative AI can be used to create personalized learning plans, generate personalized content, and provide personalized feedback. This can help students to learn more effectively by providing them with the resources and support that they need to succeed.\nGenerative AI is a powerful tool that has the potential to transform education. By providing personalized learning experiences, generative AI can help students learn more effectively and efficiently.\nHere are some of the benefits of using generative AI in education:\n\nPersonalized learning experiences: Generative AI can be used to create personalized learning experiences that are tailored to the individual student’s needs. This can help students to learn more effectively by providing them with feedback that is relevant to their current level of understanding.\nIncreased engagement: Generative AI can be used to create more engaging learning experiences. For example, generative AI can be used to create interactive games, simulations, and virtual reality experiences.\nImproved outcomes: Generative AI can help students to achieve better outcomes. For example, a study by Stanford University found that students who used a generative AI-powered tutoring system performed better on standardized tests than students who did not use the system.\n\nHere are some of the challenges of using generative AI in education:\n\nAccuracy: Generative AI models are still under development, and they can sometimes make mistakes. This is a challenge that needs to be addressed before generative AI can be widely adopted in education.\nBias: Generative AI models can be biased, reflecting the biases of the data that they are trained on. This is a challenge that needs to be addressed before generative AI can be used to create fair and equitable learning experiences.\nCost: Generative AI models can be expensive to develop and maintain. This is a challenge that needs to be addressed before generative AI can be widely adopted in education.\n\nDespite the challenges, generative AI has the potential to revolutionize education. By providing personalized learning experiences, generative AI can help students learn more effectively and efficiently."
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "Automated Essay Scoring\n\nKaggle ASAP AES Dataset: A dataset containing essays to 8 different essay prompts.\n\nAutomated Short Answer Scoring\n\nKaggle ASAP SAS Dataset: A dataset containing student responses to 10 different short constructed response prompts.\n\nFormative Feedback\n\nPERSUADE Corpus: The Persuasive Essays for Rating, Selecting, and Understanding Argumentative and Discourse Elements (PERSUADE) corpus which contains over 280,000 discourse annotations for over 25,000 argumentative essays.\nIteraTeR, R3 System, and DEIIteraTeR: A repository that provides datasets and code for preprocessing, training and testing models for Iterative Text Revision.\n\nItem Generation"
  },
  {
    "objectID": "Events.html",
    "href": "Events.html",
    "title": "Events",
    "section": "",
    "text": "Conferences\n\nAssociation of Test Publisher's Fourth EdTech and Computational Psychometrics Summit: The 2023 ATP ECPS will be a two-day virtual summit taking place on June 6th and June 7th, 2023, with an optional Pre-Conference Workshop on June 5th, focusing on how edtech & computational psychometrics’ business of assessment and innovation can help conceive digital assessments for lifelong learning. (June 5-7, 2023)\n18th Workshop on Innovative Use of NLP for Building Educational Applications: The BEA Workshop is a leading venue for NLP innovation in the context of educational applications. (July 13, 2023)"
  },
  {
    "objectID": "events.html",
    "href": "events.html",
    "title": "Events",
    "section": "",
    "text": "On this page, we aim to keep you up-to-date on events relevant to AI in Education.\nConferences\n\nAssociation of Test Publisher's Fourth EdTech and Computational Psychometrics Summit: The 2023 ATP ECPS will be a two-day virtual summit taking place on June 6th and June 7th, 2023, with an optional Pre-Conference Workshop on June 5th, focusing on how EdTech & computational psychometrics’ business of assessment and innovation can help conceive digital assessments for lifelong learning. (June 5-7, 2023)\nThe 24th International Conference on Artificial Intelligence in Education: The 24th International Conference on Artificial Intelligence in Education, AIED 2023, will take place July 3-7, 2023 in Tokyo, Japan and virtually. (3-7, July 2023)\n18th Workshop on Innovative Use of NLP for Building Educational Applications: The BEA Workshop is a leading venue for NLP innovation in the context of educational applications. (July 13, 2023)\nThe 17th International Workshop on Semantic Evaluation: SemEval is a series of international natural language processing (NLP) research workshops whose mission is to advance the current state of the art in semantic analysis and to help create high-quality annotated datasets in a range of increasingly challenging problems in natural language semantics. (July 13-14 2023).\n\nTo register an event, please use the following form: GAIME Event Registration"
  }
]