[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The recent explosion of “Generative AI” has broad and deep implications for Education Measurement. By “Generative AI” we mean algorithms that create new text, images, or sound using machine learning algorithms trained on previous existing samples of that data. This technology is already in operational use in assessments and learning solutions and is being rapidly developed.  At the same time, it brings significant challenges to foundational principles in measurement validity, fairness, and reliability. With evidence and constructs constantly recreated, and data not representative nor static, many concepts of measurement and practices to implement them need to be rethought.\nGrounding innovation with principles from measurement can help to reduce the risk of these new approaches, improve their impact on student learning, and ensure that students from minoritized communities are not harmed, without rejecting their potential value. This genie will not be put back into its bottle.  Instead, measurement experts can help shape these solutions, collaboratively identifying important areas of focus and sharing innovative solutions. \nThis special interest group (SIGIME) seeks to advance the theoretical and applied research into AI of educational measurement by bringing together data scientists, psychometricians, education researchers, and other interested stakeholders. The SIGIME will discuss current practices in using Generative AI, approaches to evaluate their precision/accuracy, and areas where more foundational research is required into the way we test and measure educational outcomes. This group seeks to create a strong professional identity and intellectual home for those interested in the use of AI in many areas, including automated scoring, item evaluation, validity studies, formative feedback, and generative AI for automated item generation. A critical initial responsibility is to ensure that there are guidelines around FATE (fair, accountable, transparent, and ethical) principles for applying AI in measurement (Harris 2023 ). Further, the interpretability of machine learning models is often a difficulty in evaluating the validity of these methods using conventional psychometric approaches, although there is active research in this area (Dorsey and Michaels 2022).\nWe suggest three initial applied areas for exploration: \n\nItem Generation. This new technology is rapidly changing the way we think about education and problem-solving. With generative AI, the ability to create an infinite item pool is within our grasp and one that is customized to the interests or social context of the learner. However, some important ethical and psychometric considerations need to be addressed. How do we filter this pool for the best items? What are our standards of validity and accuracy when there is no baseline? How should assessment item development processes be designed? It is important for those of us who understand these systems best to help educators and test developers make informed decisions about how to use generative AI fairly and appropriately.\nAutomated scoring of open-ended items. Automated Scoringis possibly the most widely used application of AI in education, and has been identified as the top use of AI published in measurement journals (Zheng et. all, 2023). There has been a major shift in the past few years in the methods used. The development and incorporation of large language models (LLMs) in automated scoring systems have led to substantial increases in scoring accuracy and increased flexibility to generalize models to new items with a lower training effort. However, LLMs are difficult to interpret and have a greater risk of bias. Since LLMs are trained on large amounts of data that is not from students (fortunately), this introduces new ways in which scoring engines could be biased. As we move forward, we need to ensure that using LLMs in automated scoring remains fair and equitable.\nFormative Feedback. In many contexts, assessment is rapidly moving from an isolated activity to one that is embedded within the learning experience. As AI methods continue to advance, an open area of research as to how we can leverage AI to provide students with improved diagnostic feedback. Integrating AI-based tools into automated writing evaluation (AWE) systems requires that the feedback returned is grounded in educational theory. Dialogue between data scientists, educators, and psychometricians is key to ensuring that AI is utilized to improve educational outcomes. A special interest group within the NCME could provide an appropriate forum for these discussions. \n\nGenerative AI is taking the world by storm, and we believe NCME can make a deep and substantive contribution to how this technology is used in education.  A special interest group on Artificial Intelligence (AI) in Measurement and Education would provide a timely forum for researchers and practitioners in the use of AI in Education and Measurement to share their work, discuss challenges, and develop best practices. \n\n\n\n\n\n\nReferences\n\nDorsey, David W., and Hillary R. Michaels. 2022. “Validity Arguments Meet Artificial Intelligence in Innovative Educational Assessment: A Discussion and Look Forward.” Journal of Educational Measurement 59 (3): 389–94. https://doi.org/10.1111/jedm.12330.\n\n\nHarris, Robert. 2023. “FATE (Fairness and Transparency) Hits the Mainstream: UK’s 5 Principles for AI Regulation.” https://feedzai.com/blog/fate-fairness-and-transparency-hits-the-mainstream-uks-5-principles-for-ai-regulation/."
  },
  {
    "objectID": "events.html",
    "href": "events.html",
    "title": "Events",
    "section": "",
    "text": "On this page, we aim to keep you up-to-date on events relevant to AI in Education."
  },
  {
    "objectID": "events.html#active-publication-opportunities",
    "href": "events.html#active-publication-opportunities",
    "title": "Events",
    "section": "Active Publication Opportunities",
    "text": "Active Publication Opportunities\nThis is a running list of potentially relevant publication opportunities for Generative AI.\n\nFuture Shock: Grappling with the Generative AI Revolution\nJournal: Harvard Data Science Review\nPublished: 11 Jul 2023\nDeadline: 25 August 2023\nURL: Call for papers\n\nArticles clarifying the nature and limitations of foundation models, large language models (LLMs), and generative AI applications. Articles exploring the wider societal risks and impacts of foundation models, LLMs, and generative AI applications.\n\n\nNCME\nDeadline: 28 August 2023 URL: here\n\n\nLeveraging Large Language Models for Assessment Support: Applications and Implications\nJournal: Computers and Education: Artificial Intelligence (Open Access) \nPublished: 28 June 2023\nDeadline: 30 October 2023\nContact: Prof. Rafael Ferreira Mello at rflm@cesar.org.br\nURL: Call for Papers\nThis special issue focuses on exploring the implications of utilizing large language models (LLMs) for educational assessment, with particular emphasis on leveraging LLMs for formative feedback provision and mitigating challenges related to academic integrity. To this end, we invite researchers from diverse fields to submit papers investigating the use of LLMs to support the assessment process. We particularly encourage empirical research that employs rigorous methodologies, such as experimental studies, case studies, and surveys, to provide evidence of the effectiveness and impact of LLMs on assessment. Additionally, we welcome theoretical papers offering a nuanced and comprehensive understanding of the topic and its educational implications (e.g., for ethics and trustworthiness). Overall, this special issue aims to advance state-of-the-art research by integrating LLMs in the assessment process and identifying key directions for future research in this promising area.\nPlease send any new entries to John Whitmer jwhitmer@fas.org and Maggie Beiting-Parrish Magdalen.Beiting@ed.gov"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to the (proposed) Special Interest Group on Artificial Intelligence in Measurement and Education (AIME) with the National Council of Measurement in Education. Our goal is to serve as an intellectual home for data scientists and psychometricians interested in the application of AI to measurement and education.\nA draft of our charter can be found here.\nOur NCME webpage can be found here.\nInterested in joining us? The signup form can be found here. We currently hold monthly meetings and are organizing a speaker series."
  },
  {
    "objectID": "literature.html",
    "href": "literature.html",
    "title": "Literature",
    "section": "",
    "text": "This is a collection of references to empirical studies, conceptual articles about LLMs in education, and other publications relevant to understanding the current moment. This is a snapshot (updated 5/25/23) of a Zotero group; read/write access available on request if you have a suggestion or would like to see the latest & greatest.\nThis is a work in progress; a current formatted version of the literature is available here"
  },
  {
    "objectID": "meetings/June14-202.html",
    "href": "meetings/June14-202.html",
    "title": "AI in Measurement and Education",
    "section": "",
    "text": "Generative Artificial Intelligence in Measurement and Education SIGIME Meeting 1\nJune 14, 2023\nDid initial introductions.\nTalked About General Meeting Norms.\nNext, Chris gave an overview of the Charter and next steps.\nChris also explained that we need to differentiate from the Big Data group but did not hear back when he asked about their goals. A member clarified that the larger purpose of that SIGIME was to combine all of the data we have in one place; to support deep learning models etc.\nJohn next shared a brainstorming slide for the different directions the SIGIME can go in, such as a speaker series or works in progress session.\nMost people were interested in that and also suggested getting Kristen DiCerbo to present as well as other people in different industries to partner with. Including the idea of code examples/tutorials.\nChris also suggested a joint Github repo for examples of this code. https://github.com/christopherormerod/gaime  \nA member pointed out that there may be people who are at more of the technical level and more of a high-level and the SIGMIE should cater to both.\nJohn also discussed the literature review/curation of Zotero for the larger group.\nChris also shared a slide of guidelines for fair use of generative AI. A member suggested in the chat that the SIGIMIE can coordinate a set of responses to Duolingo’s ethical AI standards. A member (from chat) said we need both technical details and ethical guidelines. I agree with the former that we should respond to the AI standards put out from Duolingo, but we should ultimately try to come up with standards that would apply to the field more broadly.\nOne member also suggested that we get in touch with folks from open AI community (e.g., Eleuther AI, https://www.eleuther.ai/) to see how their data curation methods and LLMs could potentially inform educational applications.\nFinally, we discussed the larger NCME endorsement process and a member said he’d talk to the larger NCME administrators at the next conference."
  },
  {
    "objectID": "open-datasets.html",
    "href": "open-datasets.html",
    "title": "Open Datasets",
    "section": "",
    "text": "Training data is required for ML; often authentic data can be difficult to come by. This is a collection of datasets that are generally useful.\nIf you have a dataset you’d like to share (or want to find one not listed here), you might consider one of the open data repositories (e.g. Google Research Datasets, EdData, Data.gov, Dataverse, ICPSR, Datashop, UCI ML Repository).\n\nAutomated Essay Scoring\n\nKaggle ASAP AES Dataset: A dataset containing essays to 8 different essay prompts.\n\n\n\nAutomated Short Answer Scoring\n\nKaggle ASAP SAS Dataset: A dataset containing student responses to 10 different short constructed response prompts.\nPowergrading Short Answer Grading Corpus: This corpus contains the original data analyzed in the following paper: Basu, Jacobs, and Vanderwende, “Powergrading: a Clustering Approach to Amplify Human Effort for Short Answer Grading,” Transactions of the ACL, 2013. Last published: October 4, 2013.\n\n\n\nFormative Feedback\n\nPERSUADE Corpus: The Persuasive Essays for Rating, Selecting, and Understanding Argumentative and Discourse Elements (PERSUADE) corpus which contains over 280,000 discourse annotations for over 25,000 argumentative essays.\nIteraTeR, R3 System, and DEIIteraTeR: A repository that provides datasets and code for preprocessing, training and testing models for Iterative Text Revision.\n\n\n\nItem Generation\n\nSQuAD: This dataset combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. While often use to train question-answering models, this dataset has also been used to help train question generation.\nFairytaleQA: The FairytaleQA dataset was created to address the gaps present in similar datasets, as existing datasets rarely distinguish fine-grained reading skills, such as the understanding of varying narrative elements. The goal of the challenge in the link is to generate high quality questions from the dataset.\n\n\n\nProcess Data for Learning Pathways\n\nEdNet - dataset of all student-system interactions collected over 2 years by Santa, a multi-platform AI tutoring service with more than 780K users in Korea available through Android, iOS and web. Details of dataset are available as a pre–print.\nHarvardX-MITx Person-Course Dataset- this dataset contains information from the first year of edX courses, which are Harvard and MIT’s Massive Open Online Courses (MOOCs). The data includes over 600,000 students and over a billion records.\nOpen University Learning Analytics dataset - contains data about courses, students and their interactions with Virtual Learning Environment (VLE) for seven selected courses (called modules). Presentations of courses start in February and October - they are marked by “B” and “J” respectively. The dataset consists of tables connected using unique identifiers. All tables are stored in the csv format.\n\n\n\nUnlabelled\n\nEvaluating Student Writing"
  }
]